{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from torch import nn\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "NUM_CLASSES = 9\n",
    "NUM_EPOCHS = 50\n",
    "IMAGE_SIZE = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preprocess = transforms.Compose([\n",
    "        transforms.Scale(IMAGE_SIZE),\n",
    "        transforms.CenterCrop(IMAGE_SIZE),\n",
    "#         transforms.RandomSizedCrop(28),\n",
    "#         transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Lenet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Lenet, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(1, 6, 3, stride=1, padding=1),\n",
    "            nn.ReLU(True),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(6, 16, 5, stride=1, padding=0),\n",
    "            nn.ReLU(True),\n",
    "            nn.MaxPool2d(2, 2)\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "#             nn.Linear(23*23*16, 1000),\n",
    "            nn.Linear(11*11*16, 120),\n",
    "#             nn.Linear(1000, 120),\n",
    "            nn.Linear(120, 9)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return F.log_softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Tnet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Tnet, self).__init__()\n",
    "        \n",
    "#         50*50*4\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 4, 1, stride=1, padding=0),\n",
    "            nn.ReLU(True),\n",
    "            nn.MaxPool2d(2, 2)\n",
    "        )\n",
    "#         50*50*16\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, 3, stride=1, padding=1),\n",
    "            nn.ReLU(True),\n",
    "            nn.MaxPool2d(2, 2)\n",
    "        )\n",
    "#         50*50*8\n",
    "        self.conv5 = nn.Sequential(\n",
    "            nn.Conv2d(3, 8, 5, stride=1, padding=2),\n",
    "            nn.ReLU(True),\n",
    "            nn.MaxPool2d(2, 2)\n",
    "        )\n",
    "    \n",
    "        \n",
    "        \n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(25*25*28, 1000),\n",
    "            nn.Linear(1000, 120),\n",
    "#             nn.Linear(512, 160),\n",
    "            nn.Linear(120, 9)\n",
    "        )\n",
    "    def inception(self, x):\n",
    "        a = self.conv1(x)\n",
    "#         print(a.size())\n",
    "        b = self.conv3(x)\n",
    "#         print(b.size())\n",
    "        c = self.conv5(x)\n",
    "#         print(c.size())\n",
    "        x = torch.cat((a, b, c), 1) # 50*50*28\n",
    "        x = nn.MaxPool2d(2, 2)(x) # 25*25*28\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.inception(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return F.log_softmax(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# if __name__ == '__main__':\n",
    "from torch.autograd import Variable\n",
    "from torch.optim import Adam\n",
    "from torchnet.engine import Engine\n",
    "from torchnet.logger import VisdomPlotLogger, VisdomLogger\n",
    "from torchvision.utils import make_grid\n",
    "from torchvision.datasets.mnist import MNIST\n",
    "from tqdm import tqdm\n",
    "from tqdm import tqdm_notebook\n",
    "import torchnet as tnt\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "def grayimage_loader(path):\n",
    "    return Image.open(path).convert('L')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize model\n",
    "model = Tnet().cuda()\n",
    "print('# parameters: ', sum(param.numel() for param in model.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = Adam(model.parameters(), lr=1e-3)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# criterion = nn.MSELoss(size_average=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "engine = Engine()\n",
    "meter_loss = tnt.meter.AverageValueMeter()\n",
    "meter_accuracy = tnt.meter.ClassErrorMeter(accuracy=True)\n",
    "confusion_meter = tnt.meter.ConfusionMeter(NUM_CLASSES, normalized=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_loss_logger = VisdomPlotLogger('line', opts={'title': 'Train Loss'})\n",
    "train_error_logger = VisdomPlotLogger('line', opts={'title': 'Train Accuracy'})\n",
    "test_loss_logger = VisdomPlotLogger('line', opts={'title': 'Test Loss'})\n",
    "test_accuracy_logger = VisdomPlotLogger('line', opts={'title': 'Test Accuracy'})\n",
    "confusion_logger = VisdomLogger('heatmap', opts={'title': 'Confusion Matrix',\n",
    "                                                  'columnnames': list(range(NUM_CLASSES)),\n",
    "                                                  'rownames': list(range(NUM_CLASSES)),\n",
    "                                                  })\n",
    "# ground_truth_logger = VisdomLogger('image', opts={'title': 'Ground Truth'})\n",
    "# reconstruction_logger = VisdomLogger('image', opts={'title': 'Reconstruction'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def augmentation(x, max_shift=2):\n",
    "    _, _, height, width = x.size()\n",
    "\n",
    "    h_shift, w_shift = np.random.randint(-max_shift, max_shift + 1, size=2)\n",
    "    source_height_slice = slice(max(0, h_shift), h_shift + height)\n",
    "    source_width_slice = slice(max(0, w_shift), w_shift + width)\n",
    "    target_height_slice = slice(max(0, -h_shift), -h_shift + height)\n",
    "    target_width_slice = slice(max(0, -w_shift), -w_shift + width)\n",
    "\n",
    "    shifted_image = torch.zeros(*x.size())\n",
    "    shifted_image[:, :, source_height_slice, source_width_slice] = x[:, :, target_height_slice, target_width_slice]\n",
    "    return shifted_image.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_iterator(mode):\n",
    "#     dataset = MNIST(root='../data', download=True, train=mode)\n",
    "    dataset = {x: datasets.ImageFolder('D:/Anaconda3/Scripts/lwz/category_new_9/' + x, preprocess)\n",
    "              for x in ['train', 'test']}\n",
    "#     data = dataset['train' if mode else 'test']\n",
    "#     labels = getattr(dataset[], 'train' if mode else 'test')\n",
    "#     tensor_dataset = tnt.dataset.TensorDataset([data, labels])\n",
    "    dataloader = DataLoader(dataset['train' if mode else 'test'], \n",
    "                            num_workers=4, \n",
    "                            batch_size=BATCH_SIZE, \n",
    "                            shuffle=mode)\n",
    "#     data, labels = dataloader\n",
    "#     tensor_dataset = tnt.dataset.TensorDataset([data, labels])\n",
    "    \n",
    "#     print(tensor_dataset.parallel(batch_size=BATCH_SIZE, num_workers=4, shuffle=mode))\n",
    "#     return tensor_dataset.parallel(batch_size=BATCH_SIZE, num_workers=4, shuffle=mode)\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def processor(sample):\n",
    "    data, labels, training = sample\n",
    "    \n",
    "#     data = augmentation(data.unsqueeze(1).float() / 255.0)\n",
    "#     data = preprocess(data)\n",
    "#     data.unsqueeze_(0)\n",
    "#     data = data.unsqueeze(1).float() / 255.0\n",
    "#     labels = torch.LongTensor(labels)\n",
    "    \n",
    "#     labels = torch.sparse.torch.eye(NUM_CLASSES).index_select(dim=0, index=labels)\n",
    "    \n",
    "    data = Variable(data.cuda())\n",
    "    labels = Variable(labels.cuda())\n",
    "    \n",
    "    if training:\n",
    "        model.train(True)\n",
    "    else:\n",
    "        model.train(False)\n",
    "        \n",
    "    outputs = model(data)\n",
    "    loss = criterion(outputs, labels)\n",
    "    \n",
    "    return loss, outputs\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reset_meters():\n",
    "    meter_accuracy.reset()\n",
    "    meter_loss.reset()\n",
    "    confusion_meter.reset()\n",
    "\n",
    "def on_sample(state):\n",
    "    state['sample'].append(state['train'])\n",
    "    \n",
    "def on_forward(state):\n",
    "    meter_accuracy.add(state['output'].data, torch.LongTensor(state['sample'][1]))\n",
    "    confusion_meter.add(state['output'].data, torch.LongTensor(state['sample'][1]))\n",
    "    meter_loss.add(state['loss'].data[0])\n",
    "    \n",
    "def on_start_epoch(state):\n",
    "    reset_meters()\n",
    "    state['iterator'] = tqdm_notebook(state['iterator'])\n",
    "#     state['iterator'] = state['iterator']\n",
    "\n",
    "def on_end_epoch(state):\n",
    "    print('[Epoch {}] Training Loss: {:.4f} (Acc: {:.2f})'.format(\n",
    "        state['epoch'], meter_loss.value()[0], meter_accuracy.value()[0]\n",
    "    ))\n",
    "    \n",
    "    train_loss_logger.log(state['epoch'], meter_loss.value()[0])\n",
    "    train_error_logger.log(state['epoch'], meter_accuracy.value()[0])\n",
    "    \n",
    "    reset_meters()\n",
    "    \n",
    "    engine.test(processor, get_iterator(False))\n",
    "    test_loss_logger.log(state['epoch'], meter_loss.value()[0])\n",
    "    test_accuracy_logger.log(state['epoch'], meter_accuracy.value()[0])\n",
    "    confusion_logger.log(confusion_meter.value())\n",
    "    \n",
    "    print('[Epoch {}] Testing Loss: {:4f} (Acc: {:.2f})'.format(\n",
    "        state['epoch'], meter_loss.value()[0], meter_accuracy.value()[0]\n",
    "    ))\n",
    "    \n",
    "    if state['epoch'] % 10 == 0:\n",
    "        torch.save(model.state_dict(), 'epochs/epoch_%d.pt' % state['epoch'])\n",
    "    \n",
    "    test_sample = next(iter(get_iterator(False)))\n",
    "    \n",
    "#     ground_truth = (test_sample[0].unsqueeze(1).float() / 255.0)\n",
    "#     _, reconstructions = model(Variable(ground_truth).cuda())\n",
    "#     reconstruction = reconstructions.cpu().view_as(ground_truth).data\n",
    "\n",
    "#     ground_truth_logger.log(\n",
    "#             make_grid(ground_truth, nrow=int(BATCH_SIZE ** 0.5), normalize=True, range=(0, 1)).numpy())\n",
    "#     reconstruction_logger.log(\n",
    "#             make_grid(reconstruction, nrow=int(BATCH_SIZE ** 0.5), normalize=True, range=(0, 1)).numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine.hooks['on_sample'] = on_sample\n",
    "engine.hooks['on_forward'] = on_forward\n",
    "engine.hooks['on_start_epoch'] = on_start_epoch\n",
    "engine.hooks['on_end_epoch'] = on_end_epoch\n",
    "\n",
    "engine.train(processor, get_iterator(True), maxepoch=NUM_EPOCHS, optimizer=optimizer)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
